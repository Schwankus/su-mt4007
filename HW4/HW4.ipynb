{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fc3dc-195b-49ac-9fab-b66c4e351165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sqlite3 as sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2559793-f1ca-40b1-9c5f-e423a78d238f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Joining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12517ae-3108-4308-9f16-9328a111bdbb",
   "metadata": {},
   "source": [
    "First, we load the raw cellphone data and convert it. this is using the same code I made in the last homework, where NaNs are forward-filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e2341b46-2814-4391-a1d8-fa0372aae223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell = pd.read_csv(\"https://raw.githubusercontent.com/su-mt4007/data/refs/heads/main/cell_phones_total.csv\")\n",
    "cell.set_index(\"iso-3\", inplace = True)\n",
    "for col in cell:\n",
    "    if len(cell[col].unique()) <= 2:\n",
    "        cell[col].fillna(0, inplace= True)\n",
    "        \n",
    "def str_to_number(x, sizes = {\"k\" : 10**3, \"K\" : 10**3\n",
    "                     , \"m\" : 10**6, \"M\": 10**6\n",
    "                     , \"b\": 10**9, \"B\" : 10**9}):\n",
    "    \n",
    "    # Takes a number expressed in the form (number)(letter) and converts it into the corresponding number using the \"sizes dictionary\"\n",
    "    \n",
    "    num = re.match(r\"[0-9\\.]+\" , str(x))\n",
    "    l = re.search(r\".$\", str(x))\n",
    "    \n",
    "    # If both num and l are successful matches, we have a string of the correct form to convert\n",
    "    if num and l:\n",
    "        # accessing the strings we found\n",
    "        num = num.group(0)\n",
    "        l = l.group(0)\n",
    "        \n",
    "        # adding the results as a number\n",
    "        if l in sizes.keys():\n",
    "                return float(num) * sizes[l]\n",
    "        else: \n",
    "                return float(num)\n",
    "\n",
    "    else:\n",
    "        return float(x)\n",
    "        \n",
    "def df_to_numbers(df):\n",
    "    return df.map(str_to_number, na_action = \"ignore\")\n",
    "    \n",
    "cell = df_to_numbers(cell)\n",
    "cell.ffill(axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b46a47-e47c-4397-9a0c-3409a8e3e4cc",
   "metadata": {},
   "source": [
    "Now let's load the population data and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1aa31819-b888-4406-b269-e56bd3987b25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso-3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABW</th>\n",
       "      <td>54608.0</td>\n",
       "      <td>55811.0</td>\n",
       "      <td>56682.0</td>\n",
       "      <td>57475.0</td>\n",
       "      <td>58178.0</td>\n",
       "      <td>58782.0</td>\n",
       "      <td>59291.0</td>\n",
       "      <td>59522.0</td>\n",
       "      <td>59471.0</td>\n",
       "      <td>59330.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101288.0</td>\n",
       "      <td>102112.0</td>\n",
       "      <td>102880.0</td>\n",
       "      <td>103594.0</td>\n",
       "      <td>104257.0</td>\n",
       "      <td>104874.0</td>\n",
       "      <td>105439.0</td>\n",
       "      <td>105962.0</td>\n",
       "      <td>106442.0</td>\n",
       "      <td>106585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFE</th>\n",
       "      <td>130692579.0</td>\n",
       "      <td>134169237.0</td>\n",
       "      <td>137835590.0</td>\n",
       "      <td>141630546.0</td>\n",
       "      <td>145605995.0</td>\n",
       "      <td>149742351.0</td>\n",
       "      <td>153955516.0</td>\n",
       "      <td>158313235.0</td>\n",
       "      <td>162875171.0</td>\n",
       "      <td>167596160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>537792950.0</td>\n",
       "      <td>552530654.0</td>\n",
       "      <td>567892149.0</td>\n",
       "      <td>583651101.0</td>\n",
       "      <td>600008424.0</td>\n",
       "      <td>616377605.0</td>\n",
       "      <td>632746570.0</td>\n",
       "      <td>649757148.0</td>\n",
       "      <td>667242986.0</td>\n",
       "      <td>685112979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>8622466.0</td>\n",
       "      <td>8790140.0</td>\n",
       "      <td>8969047.0</td>\n",
       "      <td>9157465.0</td>\n",
       "      <td>9355514.0</td>\n",
       "      <td>9565147.0</td>\n",
       "      <td>9783147.0</td>\n",
       "      <td>10010030.0</td>\n",
       "      <td>10247780.0</td>\n",
       "      <td>10494489.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29249157.0</td>\n",
       "      <td>30466479.0</td>\n",
       "      <td>31541209.0</td>\n",
       "      <td>32716210.0</td>\n",
       "      <td>33753499.0</td>\n",
       "      <td>34636207.0</td>\n",
       "      <td>35643418.0</td>\n",
       "      <td>36686784.0</td>\n",
       "      <td>37769499.0</td>\n",
       "      <td>38972230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFW</th>\n",
       "      <td>97256290.0</td>\n",
       "      <td>99314028.0</td>\n",
       "      <td>101445032.0</td>\n",
       "      <td>103667517.0</td>\n",
       "      <td>105959979.0</td>\n",
       "      <td>108336203.0</td>\n",
       "      <td>110798486.0</td>\n",
       "      <td>113319950.0</td>\n",
       "      <td>115921723.0</td>\n",
       "      <td>118615741.0</td>\n",
       "      <td>...</td>\n",
       "      <td>366489204.0</td>\n",
       "      <td>376797999.0</td>\n",
       "      <td>387204553.0</td>\n",
       "      <td>397855507.0</td>\n",
       "      <td>408690375.0</td>\n",
       "      <td>419778384.0</td>\n",
       "      <td>431138704.0</td>\n",
       "      <td>442646825.0</td>\n",
       "      <td>454306063.0</td>\n",
       "      <td>466189102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>5357195.0</td>\n",
       "      <td>5441333.0</td>\n",
       "      <td>5521400.0</td>\n",
       "      <td>5599827.0</td>\n",
       "      <td>5673199.0</td>\n",
       "      <td>5736582.0</td>\n",
       "      <td>5787044.0</td>\n",
       "      <td>5827503.0</td>\n",
       "      <td>5868203.0</td>\n",
       "      <td>5928386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24259111.0</td>\n",
       "      <td>25188292.0</td>\n",
       "      <td>26147002.0</td>\n",
       "      <td>27128337.0</td>\n",
       "      <td>28127721.0</td>\n",
       "      <td>29154746.0</td>\n",
       "      <td>30208628.0</td>\n",
       "      <td>31273533.0</td>\n",
       "      <td>32353588.0</td>\n",
       "      <td>33428486.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1960         1961         1962         1963         1964  \\\n",
       "iso-3                                                                    \n",
       "ABW        54608.0      55811.0      56682.0      57475.0      58178.0   \n",
       "AFE    130692579.0  134169237.0  137835590.0  141630546.0  145605995.0   \n",
       "AFG      8622466.0    8790140.0    8969047.0    9157465.0    9355514.0   \n",
       "AFW     97256290.0   99314028.0  101445032.0  103667517.0  105959979.0   \n",
       "AGO      5357195.0    5441333.0    5521400.0    5599827.0    5673199.0   \n",
       "\n",
       "              1965         1966         1967         1968         1969  ...  \\\n",
       "iso-3                                                                   ...   \n",
       "ABW        58782.0      59291.0      59522.0      59471.0      59330.0  ...   \n",
       "AFE    149742351.0  153955516.0  158313235.0  162875171.0  167596160.0  ...   \n",
       "AFG      9565147.0    9783147.0   10010030.0   10247780.0   10494489.0  ...   \n",
       "AFW    108336203.0  110798486.0  113319950.0  115921723.0  118615741.0  ...   \n",
       "AGO      5736582.0    5787044.0    5827503.0    5868203.0    5928386.0  ...   \n",
       "\n",
       "              2011         2012         2013         2014         2015  \\\n",
       "iso-3                                                                    \n",
       "ABW       101288.0     102112.0     102880.0     103594.0     104257.0   \n",
       "AFE    537792950.0  552530654.0  567892149.0  583651101.0  600008424.0   \n",
       "AFG     29249157.0   30466479.0   31541209.0   32716210.0   33753499.0   \n",
       "AFW    366489204.0  376797999.0  387204553.0  397855507.0  408690375.0   \n",
       "AGO     24259111.0   25188292.0   26147002.0   27128337.0   28127721.0   \n",
       "\n",
       "              2016         2017         2018         2019         2020  \n",
       "iso-3                                                                   \n",
       "ABW       104874.0     105439.0     105962.0     106442.0     106585.0  \n",
       "AFE    616377605.0  632746570.0  649757148.0  667242986.0  685112979.0  \n",
       "AFG     34636207.0   35643418.0   36686784.0   37769499.0   38972230.0  \n",
       "AFW    419778384.0  431138704.0  442646825.0  454306063.0  466189102.0  \n",
       "AGO     29154746.0   30208628.0   31273533.0   32353588.0   33428486.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = pd.read_csv(\"https://raw.githubusercontent.com/su-mt4007/data/refs/heads/main/pop_data.csv\").drop(columns = \"Unnamed: 0\").set_index(\"iso-3\")\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ccaba-b33f-4be2-a9d5-1920af0927fe",
   "metadata": {},
   "source": [
    "There are no large swathes of missing values like in the cell phone data, so we'll have to take a closer look to find the missing values. In the following code i pick all rows that have at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a36bf7bb-b894-4286-85ab-a80a6d8bd0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso-3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3882986.0</td>\n",
       "      <td>3979998.0</td>\n",
       "      <td>4076708.0</td>\n",
       "      <td>4173398.0</td>\n",
       "      <td>4270092.0</td>\n",
       "      <td>4367088.0</td>\n",
       "      <td>4454805.0</td>\n",
       "      <td>4569087.0</td>\n",
       "      <td>4685306.0</td>\n",
       "      <td>4803269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  ...  \\\n",
       "iso-3                                                              ...   \n",
       "INX     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "PSE     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "            2011       2012       2013       2014       2015       2016  \\\n",
       "iso-3                                                                     \n",
       "INX          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "PSE    3882986.0  3979998.0  4076708.0  4173398.0  4270092.0  4367088.0   \n",
       "\n",
       "            2017       2018       2019       2020  \n",
       "iso-3                                              \n",
       "INX          NaN        NaN        NaN        NaN  \n",
       "PSE    4454805.0  4569087.0  4685306.0  4803269.0  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop[pop.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfa52c-ba91-421a-aa2a-237faf7dd7e5",
   "metadata": {},
   "source": [
    "Only two rows have any missing values, meaning all others already have workable data. Now we have to decide what to do with these two rows. First let's take acloser look at `INX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "da6eabce-f137-4bb2-bba7-b352b5670a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.loc[pop.index == \"INX\"].squeeze().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce567c-b61d-4181-a49d-8a0a83e63042",
   "metadata": {},
   "source": [
    "We can see that`INX` has not a single non-`NaN` value in it. As such, we have no information to interpolate or otherwise fix the data, we will have to remove the row.\n",
    "\n",
    "Next we'll take a look at the data for `PSE`. This is the country code for Palestine, which according to wikipedia declared their independance 1988. This explains what we see if we remove the `Nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4006bbce-38ab-4a7a-acbf-5c5fb375eb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990    1978248.0\n",
       "1991    2068845.0\n",
       "1992    2163591.0\n",
       "1993    2262676.0\n",
       "1994    2366298.0\n",
       "1995    2474666.0\n",
       "1996    2587997.0\n",
       "1997    2706518.0\n",
       "1998    2776568.0\n",
       "1999    2848431.0\n",
       "2000    2922153.0\n",
       "2001    2997784.0\n",
       "2002    3075373.0\n",
       "2003    3154969.0\n",
       "2004    3236626.0\n",
       "2005    3320396.0\n",
       "2006    3406334.0\n",
       "2007    3494496.0\n",
       "2008    3591977.0\n",
       "2009    3689099.0\n",
       "2010    3786161.0\n",
       "2011    3882986.0\n",
       "2012    3979998.0\n",
       "2013    4076708.0\n",
       "2014    4173398.0\n",
       "2015    4270092.0\n",
       "2016    4367088.0\n",
       "2017    4454805.0\n",
       "2018    4569087.0\n",
       "2019    4685306.0\n",
       "2020    4803269.0\n",
       "Name: PSE, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.loc[pop.index == \"PSE\"].squeeze().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674fbf5-cf47-400d-b51a-ad6478c294a8",
   "metadata": {},
   "source": [
    "The `NaN` values end in 1990, just after Palestine declared independance. Thus, it is reasonable to set these values to 0, as there was no state of Palestine before then. However, for 1988 and 1989, I will backfill these values with the value for 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dde6c0c9-3368-4dae-94b6-ed8e3a0181e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# backfill 1988 and 1989\n",
    "pop[\"PSE\"] = pop.loc[pop.index == \"PSE\"].squeeze().bfill(limit = 2)\n",
    "# Remove INX and fill NaNs of PSE\n",
    "pop = pop.drop(axis = 0, index = \"INX\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3203ff22-7d37-4740-bb10-0d19abffa1fb",
   "metadata": {},
   "source": [
    "Now to merge our two dataframes we give them a common name for their collumns; \"year\", and pivot them to the same long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "18662068-0b3b-48d0-94ff-3e2ff8afcdaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso-3</th>\n",
       "      <th>year</th>\n",
       "      <th>n_cellphones</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59471.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso-3  year  n_cellphones  population\n",
       "0   ABW  1960           0.0     54608.0\n",
       "1   ABW  1965           0.0     58782.0\n",
       "2   ABW  1966           0.0     59291.0\n",
       "3   ABW  1967           0.0     59522.0\n",
       "4   ABW  1968           0.0     59471.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give columns name\n",
    "pop.columns.name = \"year\"\n",
    "cell.columns.name = \"year\"\n",
    "newdf = pd.merge(cell.stack().reset_index().rename(columns={0: \"n_cellphones\"}),\n",
    "                 pop.stack().reset_index().rename(columns={0: \"population\"}))\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab40c9b-22e1-43ec-bccb-a9db07df8245",
   "metadata": {},
   "source": [
    "To change `iso-3` to the corresponding country names: we load the country data that pairs them and merge (changing columns names from country data as needed). This way we have a column of country names that matches with the iso-3 names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "06cc8d25-ac2f-4d08-8bec-72ea94a50369",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso-3</th>\n",
       "      <th>year</th>\n",
       "      <th>n_cellphones</th>\n",
       "      <th>population</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54608.0</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58782.0</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59291.0</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59522.0</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59471.0</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso-3  year  n_cellphones  population country\n",
       "0   ABW  1960           0.0     54608.0   Aruba\n",
       "1   ABW  1965           0.0     58782.0   Aruba\n",
       "2   ABW  1966           0.0     59291.0   Aruba\n",
       "3   ABW  1967           0.0     59522.0   Aruba\n",
       "4   ABW  1968           0.0     59471.0   Aruba"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = pd.read_csv(\"https://raw.githubusercontent.com/su-mt4007/data/refs/heads/main/country_data.csv\")[[\"name\",\"alpha-3\"]]\n",
    "count.rename(columns={\"alpha-3\":\"iso-3\",\"name\":\"country\"}, inplace = 1)\n",
    "newdf = pd.merge(newdf,count)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774baf94-a68d-4ed9-8601-498a534942d7",
   "metadata": {},
   "source": [
    "Now we  add a column with cellphones per person (it is unnamed since we won't need a name soon). Then we remove the three columns we no longer need. We also set the index to be a multi-index of year and country so we can unstack it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c4c2e8e8-af98-4935-be22-fabd0e190b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <th>Aruba</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <th>Aruba</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <th>Aruba</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <th>Aruba</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <th>Aruba</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 \n",
       "year country     \n",
       "1960 Aruba    0.0\n",
       "1965 Aruba    0.0\n",
       "1966 Aruba    0.0\n",
       "1967 Aruba    0.0\n",
       "1968 Aruba    0.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[\"\"] = newdf[\"n_cellphones\"] / newdf[\"population\"]\n",
    "newdf.drop(columns=[\"n_cellphones\",\"population\",\"iso-3\"],inplace = True)\n",
    "newdf.set_index([\"year\",\"country\"], inplace = True)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5c681-6f1d-485b-8a29-e5824ab32850",
   "metadata": {},
   "source": [
    "The following is to make the columns we get after unstacking into values instead of tuples. I have no idea why, but unstacking gives us multi-index columns of the form (\"\",country). This way we can easily select columns later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b43a8a10-034f-49eb-934c-ce9446cff2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newdf = newdf.unstack()\n",
    "newdf.columns = newdf.columns.get_level_values(1)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa03e03-7659-425a-9a8f-62fe72819e15",
   "metadata": {},
   "source": [
    "Finally, to produce the table that was asked for, we find the countries with the five highest phone-to-person ratio by sqeezing our row for 2019 and finding the three biggest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "22ef9b1f-2a9a-4ff9-82d0-5ede13dbb738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Macao                   3.284849\n",
       "Hong Kong               2.863650\n",
       "United Arab Emirates    2.127739\n",
       "Antigua and Barbuda     1.997460\n",
       "Seychelles              1.987196\n",
       "Name: 2019, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.loc[newdf.index == \"2019\"]\\\n",
    "    .squeeze()\\\n",
    "    .sort_values(ascending = False)\\\n",
    "    .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c37a36-7d22-4169-9c97-3abbfd56a942",
   "metadata": {},
   "source": [
    "Now we can select these five countries and get the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b355b74b-abe3-4f27-91ec-72384347027d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>country</th>\n",
       "      <th>Macao</th>\n",
       "      <th>Hong Kong</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Seychelles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>3.088231</td>\n",
       "      <td>2.290401</td>\n",
       "      <td>2.007424</td>\n",
       "      <td>1.956838</td>\n",
       "      <td>1.584260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>3.143510</td>\n",
       "      <td>2.398931</td>\n",
       "      <td>2.212521</td>\n",
       "      <td>1.987545</td>\n",
       "      <td>1.605459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>3.210102</td>\n",
       "      <td>2.488773</td>\n",
       "      <td>2.183431</td>\n",
       "      <td>2.019337</td>\n",
       "      <td>1.742433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3.348741</td>\n",
       "      <td>2.670209</td>\n",
       "      <td>2.199084</td>\n",
       "      <td>2.008164</td>\n",
       "      <td>1.849900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>3.284849</td>\n",
       "      <td>2.863650</td>\n",
       "      <td>2.127739</td>\n",
       "      <td>1.997460</td>\n",
       "      <td>1.987196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "country     Macao  Hong Kong  United Arab Emirates  Antigua and Barbuda  \\\n",
       "year                                                                      \n",
       "2015     3.088231   2.290401              2.007424             1.956838   \n",
       "2016     3.143510   2.398931              2.212521             1.987545   \n",
       "2017     3.210102   2.488773              2.183431             2.019337   \n",
       "2018     3.348741   2.670209              2.199084             2.008164   \n",
       "2019     3.284849   2.863650              2.127739             1.997460   \n",
       "\n",
       "country  Seychelles  \n",
       "year                 \n",
       "2015       1.584260  \n",
       "2016       1.605459  \n",
       "2017       1.742433  \n",
       "2018       1.849900  \n",
       "2019       1.987196  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[[\"Macao\",\"Hong Kong\",\"United Arab Emirates\",\"Antigua and Barbuda\",\"Seychelles\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6112790-ce3e-4ad1-85cf-688ba02496b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f359ca-2e03-4d51-b6b5-014536684644",
   "metadata": {},
   "source": [
    "First, let's connect to the database and create our cursor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "871e03ab-30c8-4c1f-8b5d-50986ec42e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn = sql.connect(\"user_actions.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4039005-120b-481b-b995-459b39ef367d",
   "metadata": {},
   "source": [
    "Now we'll take a look at our database and see what our variables are (not sure how to fins these names normally but fetching from master gives it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f1a69c7-2ea4-4313-82a4-6b7fea6343bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('table',\n",
       " 'user_actions',\n",
       " 'user_actions',\n",
       " 2,\n",
       " 'CREATE TABLE user_actions (\\n    user_id INTEGER,\\n    username TEXT,\\n    email TEXT,\\n    action TEXT,\\n    timestamp TEXT\\n)')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM sqlite_master\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a41e0-8410-4251-a517-52a91ba00d52",
   "metadata": {},
   "source": [
    "The last value shows the five variables we have to work with. If we fetch from the data we see some examples of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7784674-8694-44cd-a97a-cb62d15c00a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 'user34', 'user34@email.com', 'signup', '2015-02-04 14:38:47')\n",
      "(28, 'user28', 'user28@email.com', 'signup', '2015-03-09 11:55:33')\n",
      "(27, 'user27', 'user27@email.com', 'login', '2015-04-17 14:48:31')\n",
      "(27, 'user27', 'user27@email.com', 'login', '2015-04-21 13:22:14')\n",
      "(27, 'user27', 'user27@email.com', 'reset_password', '2015-04-25 16:30:15')\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM user_actions\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "for data in cursor.fetchmany(5):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9de5f-ffbd-47e2-b38e-5a68f988b698",
   "metadata": {},
   "source": [
    "To find those that have signed up is simple, we just add a condition to our query and add all names we see in the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f97b56-1281-4289-8454-255f095fd820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user34',\n",
       " 'user28',\n",
       " 'user1',\n",
       " 'user24',\n",
       " 'user15',\n",
       " 'user20',\n",
       " 'user18',\n",
       " 'user25',\n",
       " 'user3',\n",
       " 'user9',\n",
       " 'user27',\n",
       " 'user16',\n",
       " 'user17',\n",
       " 'user4',\n",
       " 'user8',\n",
       " 'user13',\n",
       " 'user19',\n",
       " 'user31',\n",
       " 'user10',\n",
       " 'user23',\n",
       " 'user11',\n",
       " 'user33',\n",
       " 'user12',\n",
       " 'user29',\n",
       " 'user21',\n",
       " 'user6',\n",
       " 'user14',\n",
       " 'user30',\n",
       " 'user7',\n",
       " 'user26',\n",
       " 'user22',\n",
       " 'user5',\n",
       " 'user35',\n",
       " 'user2',\n",
       " 'user32']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM user_actions\n",
    "WHERE action = \"signup\"\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "names_signup = []\n",
    "for data in cursor.fetchall():\n",
    "    # data[1] is the username variable\n",
    "    name = data[1]\n",
    "    if name not in names_signup:\n",
    "        names_signup.append(name)\n",
    "names_signup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb1e78-460e-4c10-a96d-95b169483be1",
   "metadata": {},
   "source": [
    "If we want to count the number of log entries per user we can make a dictionary with names as keys and increment its value everytime that name appears in an entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "30494976-7172-460d-bdc0-89b4c504520e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user13    470\n",
       "user6     457\n",
       "user4     436\n",
       "user35    394\n",
       "user31    389\n",
       "user16    379\n",
       "user17    367\n",
       "user20    362\n",
       "user7     362\n",
       "user8     329\n",
       "user11    328\n",
       "user21    323\n",
       "user14    320\n",
       "user23    309\n",
       "user22    275\n",
       "user26    217\n",
       "user27    211\n",
       "user12    209\n",
       "user5     192\n",
       "user34    180\n",
       "user10    170\n",
       "user30    165\n",
       "user24    162\n",
       "user2     149\n",
       "user25    136\n",
       "user18    122\n",
       "user9     118\n",
       "user3     108\n",
       "user1     104\n",
       "user28     91\n",
       "user19     58\n",
       "user29     49\n",
       "user15     35\n",
       "user33     32\n",
       "user32     32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM user_actions\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "\n",
    "count = {}\n",
    "for data in cursor.fetchall():\n",
    "    name = data[1]\n",
    "    if name not in count.keys():\n",
    "        count[name] = 1\n",
    "    else:\n",
    "        count[name] += 1\n",
    "        \n",
    "pd.Series(count).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875ae6f-df05-4cf2-bb94-272c16c9ecf3",
   "metadata": {},
   "source": [
    "To find all users who logged in and signed up in the same day can be done by ordering by timestamp in our query. Now all entries on the same day are quaranteed to appear next to eachother(Remember that the format of the timestamps have the date first.). My algorithm to find the users is easier to explain by in-code comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69f38acb-def8-4b35-8eff-4764eecdd0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 'user8'),\n",
       " (12, 'user12'),\n",
       " (30, 'user30'),\n",
       " (7, 'user7'),\n",
       " (22, 'user22'),\n",
       " (5, 'user5'),\n",
       " (2, 'user2'),\n",
       " (32, 'user32')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM user_actions\n",
    "WHERE action = \"signup\" OR action = \"login\"\n",
    "ORDER BY timestamp\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "users = []\n",
    "temp = {}\n",
    "date = \"\"\n",
    "\n",
    "for data in cursor.fetchall():\n",
    "    \n",
    "    # Once a new day rolls around, we discard all entries we looked at previously\n",
    "    # All timestamps have the format \"YYYY-MM-DD timestamp\", so the first 10 characters have the date, and we slice the timestamp there\n",
    "    if data[4][:10] != date:\n",
    "        temp = {}\n",
    "        date = data[4][:10]\n",
    "        \n",
    "    user = data[:2]\n",
    "    action = data[3]\n",
    "    \n",
    "    # If this is the first action by the user this day, we add the user and action to the dictionary   \n",
    "    if user not in temp.keys():\n",
    "        temp[user] = action\n",
    "    # If this is not the first action, see if it is a different action (and therefore the other of the two needed in the day)\n",
    "    # add this user to the permanent list\n",
    "    elif action != temp[user] and user not in users:\n",
    "        users.append(user)\n",
    "    \n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603612d-5e1e-4740-8b23-655df14d7392",
   "metadata": {},
   "source": [
    "While I could have logically assumed that a signup has to appear before a login, I decided to follow the assignment more literally and ignored order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca1dcd-206f-4b7c-a215-d02489323c01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b7419-112b-47a0-a4ef-650fefa248d5",
   "metadata": {},
   "source": [
    "First we load the text document into a list of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f13fdb19-40f8-4f36-b4ad-b5187c2eb170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"comments.txt\", \"r\") as f:\n",
    "    comments = f.read()\n",
    "    comments = comments.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa143a34-efc5-47ad-a1f7-d944e08eda48",
   "metadata": {},
   "source": [
    "To find all instances of a hashtag in a string we use the `re.findall` function with the regular expression `r\"#\\w+\"`. This matches any part of the string that has a hashtag followed by one or more word characters. As the character `+` is \"greedy\" it matches as many characters as possible, and so only matches the full hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f018a6d-a097-4675-92fe-77e9e9d10cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#programming', '#tips']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"#\\w+\", comments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c165b2-cf0d-4b40-9865-67e22778172c",
   "metadata": {},
   "source": [
    "To find a full string that has both `#programming` and `#python` in it I use `r.fullmatch`, which checks if the whole string metches the expression (you could also use `^` at the beginning and `$` at the end of the expression to get the same result.). The actual expression i used simply checks for either \"#python\" followed by \"#programming\" or \"#programming\" followed by \"#python\" somewhere in the string. There is definitely a more elegant and generalizable solution to this problem, but this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0472357d-0452-455e-b6ac-3a8203b04665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re.fullmatch(r\"(.*#python.*#programming.*)|(.*#python.*#programming.*)\", comments[1], re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bccecb0-8990-4cb4-a52e-bb10a0a94c0b",
   "metadata": {},
   "source": [
    "In this case no match is made since comment 2 does not contain both of those hashtags. To show that it works we try it on another comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6480b47-b923-4d32-b47d-5d9a898ae87a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment: 6. \"I learned a lot. #programming #python #tips\"\n",
      "regex: 6. \"I learned a lot. #programming #python #tips\"\n"
     ]
    }
   ],
   "source": [
    "print(\"comment: \" + comments[5])\n",
    "print(\"regex: \" + re.fullmatch(r\"(.*#python.*#programming.*)|(.*#programming.*#python.*)\", comments[5], re.I).group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f4493-60a1-4fee-b4fc-bad9bc9383ab",
   "metadata": {},
   "source": [
    "To extract all hashtags from our text I simply loop though all lines of text and use our previously made hashtag-finder, and then add the hashtags to a list if it is not already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14398d1b-bd3a-4b83-9f2b-228558b6edcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#programming',\n",
       " '#tips',\n",
       " '#coding',\n",
       " '#python',\n",
       " '#tech',\n",
       " '#data',\n",
       " '#analysis',\n",
       " '#innovation',\n",
       " '#analytics',\n",
       " '#insights',\n",
       " '#research']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = []\n",
    "\n",
    "for s in comments:\n",
    "    matches = re.findall(r\"#\\w+\", s)\n",
    "    for m in matches:\n",
    "        if m not in hashtags:\n",
    "            hashtags.append(m)\n",
    "            \n",
    "hashtags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
